<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>WebScraper.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Java-Webscrapper</a> &gt; <a href="index.source.html" class="el_package">comp3111.webscraper</a> &gt; <span class="el_source">WebScraper.java</span></div><h1>WebScraper.java</h1><pre class="source lang-java linenums">package comp3111.webscraper;

import java.net.URLEncoder;
import java.text.SimpleDateFormat;
import java.util.List;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Date;

import com.gargoylesoftware.htmlunit.WebClient;
import com.gargoylesoftware.htmlunit.html.DomAttr;
import com.gargoylesoftware.htmlunit.html.HtmlAnchor;
import com.gargoylesoftware.htmlunit.html.HtmlElement;
import com.gargoylesoftware.htmlunit.html.HtmlPage;
import java.util.Vector;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

/**
 * Class which is used to scrape the queried item from 2 portals: amazon and newyork craigslist.
 * Title or name, price, posted date, url of the item, portal of each item were scraped.
 * This class massively parallelised the posted date retrieval of amazon items and craigslist pagination
 * 	using multi-threading in java application, resulting in significantly improved performance of the webscraper.
 * HtmlUnit web driver (netscape as its default) is used for the web driver.
 * 
 * @author nwihardjo
 */
public class WebScraper {
	private static final String DEFAULT_URL = &quot;https://newyork.craigslist.org/&quot;;
	private static final String AMAZON_URL = &quot;https://www.amazon.com/&quot;;
	private WebClient client;
	private ExecutorService amazonSpiderPool;
	
	/**
	 * Default Constructor, instantiated webClient of the HtmlUnit and configured for javascript renderring
	 */
<span class="fc" id="L40">	public WebScraper() {</span>
<span class="fc" id="L41">		client = new WebClient();</span>
<span class="fc" id="L42">		client.getOptions().setCssEnabled(false);</span>
<span class="fc" id="L43">		client.getOptions().setJavaScriptEnabled(false);</span>
<span class="fc" id="L44">		client.waitForBackgroundJavaScript(100000);</span>
<span class="fc" id="L45">	}</span>

	/**
	 * Get the title of the item using a specific XPath address for each portal. Amazon could have a result
	 * 	which is not an item, known by the title of the result having different XPath address. Utilised cleanStr method to
	 *  parse / clean the title for amazon (i.e. containing [sponsored], etc).
	 * 
	 * @param item  containing one specific item from either portal
	 * @param portal which the item originated (amazon / craigslist)
	 * @return title of the item
	 */
	private static String getTitle(HtmlElement item, String portal) {
<span class="fc bfc" id="L57" title="All 2 branches covered.">		String xPathAddr = (portal == AMAZON_URL) ? &quot;.//h2[@data-attribute]&quot; : &quot;.//p[@class='result-info']/a&quot;;</span>
<span class="fc" id="L58">		HtmlElement itemTitle = (HtmlElement) item.getFirstByXPath(xPathAddr);</span>
		
		// if condition += itemTitle.asText() == &quot;&quot;
<span class="fc bfc" id="L61" title="All 2 branches covered.">		return (itemTitle == null) ? null : cleanStr(itemTitle.asText(), &quot;title&quot;);</span>
	}

	/**
	 * Get every items and its information from a single page of craigslist. Used as a method to support
	 * 	pagination feature for craigslist portal, pages were retrieved by scrape method. Called by craigslist spiders
	 * 
	 * @param page a single page of the craigslist portal
	 * @return  list of the item present in the page
	 */
	protected static ArrayList&lt;Item&gt; scrapePage(HtmlPage page) {
<span class="fc" id="L72">		List&lt;?&gt; items = (List&lt;?&gt;) page.getByXPath(&quot;//li[@class='result-row']&quot;);</span>
<span class="fc" id="L73">		ArrayList&lt;Item&gt; craigsArrayList = new ArrayList&lt;Item&gt;();</span>
<span class="fc bfc" id="L74" title="All 2 branches covered.">		for (int i = 0; i &lt; items.size(); i++) {</span>
<span class="fc" id="L75">			HtmlElement htmlItem = (HtmlElement) items.get(i);	</span>
<span class="fc" id="L76">			Item item = new Item(getTitle(htmlItem, DEFAULT_URL), getPrice(htmlItem, DEFAULT_URL), getUrl(htmlItem, DEFAULT_URL), DEFAULT_URL, </span>
<span class="fc" id="L77">					getPostedDate(htmlItem));</span>
<span class="fc" id="L78">			craigsArrayList.add(item);</span>
		}
<span class="fc" id="L80">		return craigsArrayList;</span>
	}
	
	/**
	 * Retrieve the price of an amazon's or craigslist's item based on its XPath address. For amazon item, if main price 
	 * 	present, only the main price will be used. If main price does not present, cheapest price of offers / other buying options
	 * 	, if any, will be used. If the stated price were a range, avose your Free Limited Edition Gift! erage of the price range will be used. Utilised
	 * 	cleanStr method to clean / parse the price (i.e. containing $, &quot;,&quot;, etc). If no price exists, price will be 0.
	 * 
	 * @param item HtmlElement which containing only a single item
	 * @param portal name of the portal the passed item came from
	 * @return price of the item in USD based on the condition described
	 */
	private static Double getPrice(HtmlElement item, String portal) {
		// return 0.0 if the price is not specified
<span class="fc bfc" id="L95" title="All 2 branches covered.">		if (portal == AMAZON_URL) {</span>
			// portal: amazon 
<span class="fc" id="L97">			ArrayList&lt;HtmlElement&gt; ItemWholePrice = new ArrayList&lt;HtmlElement&gt; (item.getByXPath(&quot;.//*[contains(@class, 'sx-price-whole')]&quot;));</span>
<span class="fc" id="L98">			ArrayList&lt;HtmlElement&gt; ItemFractionalPrice = new ArrayList&lt;HtmlElement&gt; (item.getByXPath(&quot;.//*[contains(@class, 'sx-price-fractional')]&quot;));</span>
			
<span class="fc bfc" id="L100" title="All 4 branches covered.">			if (ItemWholePrice.size() == 0 || ItemFractionalPrice.size() == 0) {</span>
				// offer / other buying options price when main price does not exist
<span class="fc" id="L102">				HtmlElement offeredPrice = (HtmlElement) item.getFirstByXPath(&quot;.//*[contains(text(),'offer')]&quot;);</span>
<span class="fc bfc" id="L103" title="All 2 branches covered.">				if (offeredPrice == null) </span>
<span class="fc" id="L104">					return 0.0;</span>
				else {
<span class="fc" id="L106">					return new Double(cleanStr(offeredPrice.asText().replaceAll(&quot;\\(.*\\)&quot;, &quot;&quot;), &quot;price&quot;));</span>
				}
<span class="fc bfc" id="L108" title="All 4 branches covered.">			} else if (ItemWholePrice.size() &gt; 1 &amp;&amp; ItemFractionalPrice.size() &gt; 1) {</span>
				// range price
<span class="fc" id="L110">				Double lowPrice = new Double (cleanStr(ItemWholePrice.get(0).asText(), &quot;price&quot;) + &quot;.&quot; + ItemFractionalPrice.get(0).asText());</span>
<span class="fc" id="L111">				Double highPrice = new Double (cleanStr(ItemWholePrice.get(1).asText(), &quot;price&quot;) + &quot;.&quot; + ItemFractionalPrice.get(1).asText());</span>
<span class="fc" id="L112">				return (lowPrice + highPrice) / 2.0;</span>
			} else { 
				// main price / normal case
<span class="fc" id="L115">				return new Double (cleanStr(ItemWholePrice.get(0).asText(), &quot;price&quot;) + &quot;.&quot; + ItemFractionalPrice.get(0).asText()); }</span>
		} else {
			// portal: craigslist
<span class="fc" id="L118">			HtmlElement itemPrice = ((HtmlElement) item.getFirstByXPath(&quot;.//*[@class='result-price']&quot;));</span>
<span class="fc bfc" id="L119" title="All 2 branches covered.">			if (itemPrice == null) </span>
<span class="fc" id="L120">				return 0.0;</span>
			else 
<span class="fc" id="L122">				return new Double(cleanStr(itemPrice.asText(), &quot;price&quot;));</span>
		}
		}
	
	/**
	 * Clean or parse string based on the usage (for title or price) 
	 * 
	 * @param str string going to be parsed / cleaned
	 * @param use name of the method which call this method
	 * @return cleaned / parsed string
	 */
	private static String cleanStr(String str, String use) {
<span class="fc bfc" id="L134" title="All 2 branches covered.">		if (use == &quot;price&quot;) {</span>
<span class="fc" id="L135">			return str.replace(&quot;$&quot;, &quot;&quot;).replace(&quot;,&quot;, &quot;&quot;);</span>
		} else
<span class="fc bfc" id="L137" title="All 2 branches covered.">			return (str.startsWith(&quot;[Sponsored]&quot;)) ? str.replace(&quot;[Sponsored]&quot;, &quot;&quot;) : str;</span>
	}
	
	/**
	 * Scrape the url of the page of the item from either portal (amazon / craigslist)
	 * 
	 * @param item HtmlElement consisting of a single item
	 * @param portal name of the website where the passed item came from
	 * @return url of the item page in its respective portal
	 */
	private static String getUrl(HtmlElement item, String portal) {
<span class="fc bfc" id="L148" title="All 2 branches covered.">		String portal_url = (portal == AMAZON_URL) ? AMAZON_URL : DEFAULT_URL;</span>
<span class="fc bfc" id="L149" title="All 2 branches covered.">		String xPathAddr = (portal == AMAZON_URL) ? &quot;.//h2[@data-attribute]/parent::a&quot; : &quot;.//p[@class='result-info']/a&quot;;</span>
<span class="fc" id="L150">		HtmlAnchor itemUrl = (HtmlAnchor) item.getFirstByXPath(xPathAddr);</span>
<span class="fc bfc" id="L151" title="All 2 branches covered.">		return (itemUrl.getHrefAttribute().startsWith(portal_url)) ? itemUrl.getHrefAttribute() : </span>
<span class="fc" id="L152">			portal_url + itemUrl.getHrefAttribute();</span>
	}

	/**
	 * Retrieve the date of the time when the item is posted. This method is only implemented for craigslist only.
	 * 	Date of the posted time of amazon's items were retrieved in deploySpider function. 
	 * 
	 * @param item HtmlElement consisting of a single item
	 * @return date of when the item is posted in HKT (Hong Kong Time). Return null when there is no available information
	 * 	on the posted date.
	 */
	private static Date getPostedDate(HtmlElement item){
		try {
<span class="fc" id="L165">			DomAttr itemDate = (DomAttr) item.getFirstByXPath(&quot;.//*[@class='result-date']/@datetime&quot;);</span>
<span class="fc" id="L166">			SimpleDateFormat dateFormatting = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm&quot;);</span>
<span class="fc" id="L167">			return dateFormatting.parse(itemDate.getValue()); </span>
<span class="fc" id="L168">		} catch (Exception e) {</span>
<span class="fc" id="L169">			return null;</span>
		}
	}

	/**
	 * Sort the result (items) retrieved from both portals ascending. When two items from two portals has the same price
	 * 	the item from craigslist will go first. The items from each portal were sorted ascendingly first. 
	 * 
	 * @param amazonArrayList list of the items retrieved from amazon portal
	 * @param craigsArrayList list of the items retrieved from craigslist portal
	 * @return list of sorted items based on the condition described
	 */
	private static Vector&lt;Item&gt; sortResult(ArrayList&lt;Item&gt; amazonArrayList, ArrayList&lt;Item&gt; craigsArrayList){
<span class="fc" id="L182">		Collections.sort(amazonArrayList);</span>
<span class="fc" id="L183">		Collections.sort(craigsArrayList);</span>
<span class="fc bfc" id="L184" title="All 4 branches covered.">		if (amazonArrayList.isEmpty() &amp;&amp; !craigsArrayList.isEmpty())</span>
<span class="fc" id="L185">			return new Vector&lt;Item&gt;(craigsArrayList);</span>
<span class="fc bfc" id="L186" title="All 4 branches covered.">		else if (craigsArrayList.isEmpty() &amp;&amp; !amazonArrayList.isEmpty())</span>
<span class="fc" id="L187">			return new Vector&lt;Item&gt;(amazonArrayList);</span>
		else {
<span class="fc" id="L189">			Vector&lt;Item&gt; result = new Vector&lt;Item&gt;();</span>
<span class="fc bfc" id="L190" title="All 4 branches covered.">			for (int i=0, j=0; !amazonArrayList.isEmpty() || !craigsArrayList.isEmpty();) {</span>
<span class="fc bfc" id="L191" title="All 2 branches covered.">				if (amazonArrayList.isEmpty()) </span>
<span class="fc" id="L192">					result.add(craigsArrayList.remove(j));</span>
<span class="fc bfc" id="L193" title="All 2 branches covered.">				else if (craigsArrayList.isEmpty()) </span>
<span class="fc" id="L194">					result.add(amazonArrayList.remove(i));</span>
<span class="fc bfc" id="L195" title="All 2 branches covered.">				else if (craigsArrayList.get(j).getPrice() &gt; amazonArrayList.get(i).getPrice()) </span>
<span class="fc" id="L196">					result.add(amazonArrayList.remove(i));</span>
<span class="fc bfc" id="L197" title="All 2 branches covered.">				else if (craigsArrayList.get(j).getPrice() &lt; amazonArrayList.get(i).getPrice()) </span>
<span class="fc" id="L198">					result.add(craigsArrayList.remove(j));</span>
<span class="pc bpc" id="L199" title="1 of 2 branches missed.">				else if (craigsArrayList.get(j).getPrice() == amazonArrayList.get(i).getPrice())</span>
<span class="fc" id="L200">					result.add(craigsArrayList.remove(j));</span>
			}
<span class="fc" id="L202">			return result;</span>
		}
	}

	/**
	 * Parallelisation to retrieve the posted date of the amazon item which is stored in each of the item's page.
	 * 	Multi-threading were used to intialise multiple webclients to scrape amazon's items pages concurrently, using a 
	 * 	thread pool with the size of the number of item present in a single page of the amazon. Each thread then return the
	 * 	scraped posted date of each item and update the value of the posted date of the item. 
	 * 
	 * @param amazonArrayList list of items present in a single page of amazon portal
	 * @return same list of items passed with updated posted date value, if any
	 */
	private ArrayList&lt;Item&gt; deploySpiders(ArrayList&lt;Item&gt; amazonArrayList){
		try {
<span class="fc" id="L217">			amazonSpiderPool = Executors.newFixedThreadPool(amazonArrayList.size());</span>
<span class="fc" id="L218">			List&lt;Future&lt;Date&gt;&gt; spiders = new ArrayList&lt;Future&lt;Date&gt;&gt;();</span>
<span class="fc bfc" id="L219" title="All 2 branches covered.">			for (Item amazonItem : amazonArrayList) {</span>
<span class="fc" id="L220">				Callable&lt;Date&gt; spider = new Spider(amazonItem.getUrl());</span>
<span class="fc" id="L221">				spiders.add(amazonSpiderPool.submit(spider));</span>
<span class="fc" id="L222">			}</span>
<span class="fc bfc" id="L223" title="All 2 branches covered.">			for (int i = 0; i &lt; amazonArrayList.size(); i++) {</span>
<span class="fc" id="L224">				amazonArrayList.get(i).setPostedDate(spiders.get(i).get());</span>
			}
<span class="fc" id="L226">			amazonSpiderPool.shutdown();</span>
<span class="fc" id="L227">			return amazonArrayList;</span>
<span class="fc" id="L228">		} catch (Exception e) {</span>
<span class="fc" id="L229">			return amazonArrayList;</span>
		}
	}

	/**
	 * Main framework method which is used to scrape and handle concurrency for scraping craigslist while handling the
	 * 	pagination. Instantiate a thread pool which able to cut down the time of scraping significantly by parallelised
	 * 	the scraping
	 * @param pageStatistics integer array which contain the total number of pages and the number of searches in a page
	 * @param keyword of the search
	 * @param firstPageUrl 
	 * @return arraylist of all items scraped through all pages
	 */
	private ArrayList&lt;Item&gt; handlePagination (ArrayList&lt;Integer&gt; pageStatistics, String keyword, String firstPageUrl){
<span class="nc" id="L243">		ArrayList&lt;Item&gt; craigsArrayList = new ArrayList&lt;Item&gt;();</span>
		try {
<span class="nc" id="L245">			ExecutorService craigsSpiderPool = Executors.newFixedThreadPool(pageStatistics.get(0));</span>
<span class="nc" id="L246">			List&lt;Future&lt;ArrayList&lt;Item&gt;&gt;&gt; spiders = new ArrayList&lt;Future&lt;ArrayList&lt;Item&gt;&gt;&gt;();</span>
			
			// for scraping the first page
<span class="nc" id="L249">			Callable&lt;ArrayList&lt;Item&gt;&gt; cSpider = new craigsSpider(firstPageUrl);</span>
<span class="nc" id="L250">			spiders.add(craigsSpiderPool.submit(cSpider));</span>
					
			// scrape the next pages
<span class="nc bnc" id="L253" title="All 2 branches missed.">			for (int i = 2; i &lt;= pageStatistics.get(0); i++) {</span>
<span class="nc" id="L254">				String urlPage = DEFAULT_URL + &quot;search/sss?s=&quot; + (i-1)*pageStatistics.get(1) + &quot;&amp;query=&quot; + keyword + &quot;&amp;sort=rel&quot;;</span>
<span class="nc" id="L255">				Callable&lt;ArrayList&lt;Item&gt;&gt; cSpider_ = new craigsSpider(urlPage);</span>
<span class="nc" id="L256">				spiders.add(craigsSpiderPool.submit(cSpider_));</span>
			}
			
			// craigslist's list of items retrieval
<span class="nc bnc" id="L260" title="All 2 branches missed.">			for (int i = 0; i &lt; spiders.size(); i++) {</span>
<span class="nc" id="L261">				craigsArrayList.addAll(spiders.get(i).get());</span>
			}
<span class="nc" id="L263">			craigsSpiderPool.shutdown();		</span>
<span class="nc" id="L264">			return craigsArrayList;</span>
<span class="nc" id="L265">		} catch (Exception e) { </span>
<span class="nc" id="L266">			return craigsArrayList;</span>
		}
	}
	
	/**
	 * Scrape the page statistics given a htmlpage, used only for craigslist portal
	 * @param page
	 * @return array integer which contain the total number of pages resulted from searching the keyword, and the number
	 * 	of items in each page
	 */
	private static ArrayList&lt;Integer&gt; getPageStatistics (HtmlPage page) {
<span class="fc" id="L277">		ArrayList&lt;Integer&gt; ret = new ArrayList&lt;Integer&gt;();</span>
		
<span class="fc" id="L279">		Integer totResultCount = new Integer (((HtmlElement) page.getFirstByXPath(&quot;//span[@class='totalcount']&quot;)).asText());</span>
<span class="fc" id="L280">		String rangeResult = ((HtmlElement) page.getFirstByXPath(&quot;//span[@class='range']&quot;)).asText();</span>
<span class="fc" id="L281">		Integer numResultOnePage = new Integer (rangeResult.substring(rangeResult.lastIndexOf(&quot;-&quot;)+1).replaceAll(&quot; &quot;, &quot;&quot;));</span>
		
<span class="fc bfc" id="L283" title="All 2 branches covered.">		ret.add((totResultCount % numResultOnePage != 0) ? (totResultCount / numResultOnePage)+1 : (totResultCount/numResultOnePage));</span>
<span class="fc" id="L284">		ret.add(numResultOnePage);</span>
<span class="fc" id="L285">		return ret;</span>
	}
	
	/**
	 * Method to manage the workflow of scraping both portals based on the keyword specified. Handle amazon portal first, then the 
	 * 	craigslist sequentially. Pagination of amazon is not handled, item's posted date retrieval is done concurrently, after all
	 * 	of the items have been collected. Pagination of craigslist is handled concurrently.
	 * 
	 * @param keyword the keyword you want to search
	 * @param controller instance of which call this function, to update user on the scraping progress
	 * @return A list of Item that has found. A zero size list is return if nothing is found. Null if any exception (e.g. no connectivity)
	 */
	public List&lt;Item&gt; scrape(String keyword, Controller controller) {
		try {
			/*
			 * AMAZON SCRAPER
			 */
<span class="nc" id="L302">			controller.printConsole(&quot;Scraping amazon \n&quot;); System.out.println(&quot;   DEBUG: scraping amazon...&quot;);</span>
<span class="nc" id="L303">			String amazonUrl = AMAZON_URL+&quot;s/ref=nb_sb_noss?url=search-alias%3Daps&amp;field-keywords=&quot; + URLEncoder.encode(keyword,&quot;UTF-8&quot;);</span>
<span class="nc" id="L304">			HtmlPage amazonPage = client.getPage(amazonUrl);</span>
<span class="nc" id="L305">			List&lt;?&gt; amazonResult = (List&lt;?&gt;) amazonPage.getByXPath(&quot;//li[starts-with(@id, 'result_')]&quot;);</span>
<span class="nc" id="L306">			ArrayList&lt;Item&gt; amazonArrayList = new ArrayList&lt;Item&gt;();</span>
			
			// item retrieval
<span class="nc bnc" id="L309" title="All 2 branches missed.">			for (int i = 0; i &lt; amazonResult.size(); i++) {</span>
<span class="nc" id="L310">				HtmlElement amazonItem = (HtmlElement) amazonResult.get(i);</span>

				//non-item case
<span class="nc bnc" id="L313" title="All 2 branches missed.">				if (getTitle(amazonItem, AMAZON_URL) == null) continue;</span>
				
<span class="nc" id="L315">				Item item = new Item(getTitle(amazonItem, AMAZON_URL), getPrice(amazonItem, AMAZON_URL), getUrl(amazonItem, AMAZON_URL), AMAZON_URL, null);</span>
<span class="nc" id="L316">				amazonArrayList.add(item);</span>
			}
			// retrieve postedDate for amazonItems
<span class="nc" id="L319">			controller.printConsole(&quot;\t Scraping &quot; + amazonResult.size() + &quot; amazon's item page(s) in parallel (if any) ... \n&quot;);	</span>
<span class="nc" id="L320">			amazonArrayList = deploySpiders(amazonArrayList);</span>
			
			
			/*
			 * NEWYORK CRAIGSLIST SCRAPER
			 */
<span class="nc" id="L326">			controller.printConsole(&quot;Scraping craigslist \n&quot;); System.out.println(&quot;   DEBUG: scraping craigslist...&quot;);</span>
<span class="nc" id="L327">			String searchUrl = DEFAULT_URL + &quot;search/sss?sort=rel&amp;query=&quot; + URLEncoder.encode(keyword, &quot;UTF-8&quot;);</span>
<span class="nc" id="L328">			HtmlPage page = client.getPage(searchUrl);</span>
<span class="nc" id="L329">			ArrayList&lt;Item&gt; craigsArrayList = new ArrayList&lt;Item&gt;();</span>
		
			// handle pagination using multi-threading to support concurrency
			// check whether craigslist has any listings on the item searched
<span class="nc bnc" id="L333" title="All 2 branches missed.">			if (page.getFirstByXPath(&quot;//span[@class='totalcount']&quot;) != null) {</span>
<span class="nc" id="L334">				ArrayList&lt;Integer&gt; pageStatistics = getPageStatistics(page);</span>
<span class="nc" id="L335">				controller.printConsole(&quot;\t&quot; + pageStatistics.get(0) + &quot; page(s) of craigslist are being scraped in parallel ...&quot;);</span>
<span class="nc" id="L336">				craigsArrayList.addAll(handlePagination(pageStatistics, URLEncoder.encode(keyword, &quot;UTF-8&quot;), searchUrl));</span>
			}
			
			// sort result retrieved from both portals
<span class="nc" id="L340">			Vector&lt;Item&gt; result = sortResult(amazonArrayList, craigsArrayList);</span>
	 
<span class="nc" id="L342">			client.close();</span>
<span class="nc" id="L343">			System.out.println(&quot;DEBUG: scraping finished&quot;);</span>
<span class="nc" id="L344">			return result;</span>
<span class="fc" id="L345">		} catch (Exception e) {</span>
<span class="fc" id="L346">			System.out.println(e);</span>
<span class="fc" id="L347">			return null;</span>
		}
	}
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.1.201803210924</span></div></body></html>